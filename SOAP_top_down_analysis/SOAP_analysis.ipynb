{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plp\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from  h5py import File\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import h5py\n",
    "from HDF5er import saveXYZfromTrajGroup,MDA2HDF5,saveXYZfromTrajGroup\n",
    "import numpy\n",
    "from MDAnalysis import Universe as mdaUniverse\n",
    "from SOAPify import (saponifyGroup,\n",
    "                    createReferencesFromTrajectory,\n",
    "                    mergeReferences,\n",
    "                    SOAPdistanceNormalized,\n",
    "                    saveReferences,\n",
    "                    getReferencesFromDataset,\n",
    "                    classify\n",
    "                    )\n",
    "\n",
    "loadReferences=True\n",
    "soapReferences=True\n",
    "\n",
    "\n",
    "\n",
    "def patchBoxFromTopology(hdf5TrajFile:str,topologyFile:str):\n",
    "    u=mdaUniverse(topologyFile,atom_style=\"id type x y z\")\n",
    "    with h5py.File(hdf5TrajFile,\"a\") as workFile:\n",
    "        for key in workFile['Trajectories']:\n",
    "            tgroup=workFile[f'Trajectories/{key}']\n",
    "            tgroup['Box'][:]=[u.dimensions]*tgroup['Box'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform SOAP analysis, creating the .hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadReferences:\n",
    "    for surf in [110,211,210]:\n",
    "        for fname in [f\"{surf}_T_700.lammpsdump\" ]:\n",
    "            u=mdaUniverse(fname)#, atom_style=\"id type x y z\")\n",
    "            u.atoms.types = [\"Cu\"] * len(u.atoms)\n",
    "            print(u.coord[0])\n",
    "            MDA2HDF5(u,f\"{surf}.hdf5\",fname.split('.')[0], trajChunkSize=1000)\n",
    "            print(surf)\n",
    "if soapReferences:\n",
    "    for surf in [110,211,210]:\n",
    "        patchBoxFromTopology(f\"{surf}.hdf5\",f\"{surf}.data\")\n",
    "        with File(f\"{surf}.hdf5\",\"a\") as workFile:\n",
    "            saponifyGroup(\n",
    "            trajContainers=workFile[\"Trajectories\"],\n",
    "            SOAPoutContainers=workFile.require_group(\"SOAP\"),\n",
    "            SOAPOutputChunkDim=1000,\n",
    "            SOAPnJobs=32,\n",
    "            SOAPrcut=6,\n",
    "            SOAPnmax= 8,\n",
    "            SOAPlmax= 8,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! h5ls -r 211.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the following cell we obtain the distance matrix for the whole dictionary; color scale indicates the distance in the high-dimensional SOAP feature space (dsoap) between all SOAP environments in the Cu surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from matplotlib.pyplot import viridis, get_cmap\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "from seaborn import clustermap\n",
    "from pandas import DataFrame\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "references = {}\n",
    "with File(\"../create_reference/references.hdf5\", \"r\") as refFile:\n",
    "    g = refFile[\"testReferences\"]\n",
    "    for k in g.keys():\n",
    "        references[k] = getReferencesFromDataset(g[k])\n",
    "\n",
    "wholeData = mergeReferences(\n",
    "    references[\"111\"], references[\"110\"], references[\"211\"], references[\"210\"]\n",
    ")\n",
    "ndataset = len(wholeData)\n",
    "wholeDistances = numpy.zeros((int(ndataset * (ndataset - 1) / 2)))\n",
    "cpos = 0\n",
    "for i in range(ndataset):\n",
    "    for j in range(i + 1, ndataset):\n",
    "        wholeDistances[cpos] = SOAPdistanceNormalized(\n",
    "            wholeData.spectra[i], wholeData.spectra[j]\n",
    "        )\n",
    "        cpos += 1\n",
    "\n",
    "\n",
    "a2 = ['s$_{(111)}$','ss$_{(111)}$','b$_{(111)}$',\n",
    "      's$^{l}$$_{(110)}$','s$^{h}$$_{(110)}$','ss$^{l}$$_{(110)}$','ss$^{h}$$_{(110)}$','b$_{(110)}$',\n",
    "    's$^{l}$$_{(211)}$','s$^{m}$$_{(211)}$','s$^{h}$$_{(211)}$','ss$^{l}$$_{(211)}$','ss$^{m}$$_{(211)}$','ss$^{h}$$_{(211)}$','b$_{(211)}$',\n",
    "      's$^{l}$$_{(210)}$','s$^{m}$$_{(210)}$','s$^{h}$$_{(210)}$','ss$^{l}$$_{(210)}$','ss$^{m}$$_{(210)}$','ss$^{h}$$_{(210)}$','b$_{(210)}$'\n",
    "     ]          \n",
    "        \n",
    "        \n",
    "wfDist = DataFrame(\n",
    "    squareform(wholeDistances) #index=a2, columns=a2\n",
    ")\n",
    "\n",
    "colors = {}\n",
    "colorbytype = {}\n",
    "cmaps = {\n",
    "    \"Oranges\": get_cmap(\"Oranges\"),\n",
    "    \"Reds\": get_cmap(\"Reds\"),\n",
    "    \"Blues\": get_cmap(\"Blues\"),\n",
    "    \"Greens\": get_cmap(\"Greens\"),\n",
    "    \"GnBu\": get_cmap(\"GnBu\"),\n",
    "    \"Greys\": get_cmap(\"Greys\"),\n",
    "    \"Purples\": get_cmap(\"Purples\"),\n",
    "}\n",
    "for k, c in zip(references.keys(), [\"Greys\", \"Reds\", \"GnBu\", \"Purples\"]):\n",
    "    colors[k] = [cmaps[c](0.6) for i in range(len(references[k]))]\n",
    "    colorbytype[k] = []\n",
    "    for i in range(len(references[k])):\n",
    "        cc = \"Oranges\"\n",
    "        num = 0.6\n",
    "        if \"ss\" in references[k].names[i]:\n",
    "            cc = \"Greens\"\n",
    "        elif \"s\" in references[k].names[i]:\n",
    "            cc = \"Blues\"\n",
    "        \n",
    "        if \"lc\" in references[k].names[i]:\n",
    "            num = 0.4\n",
    "        elif \"hc\" in references[k].names[i]:\n",
    "            num = 0.8\n",
    "        colorbytype[k].append(cmaps[cc](num))\n",
    "\n",
    "cr = [] + colors[\"111\"] + colors[\"110\"] + colors[\"211\"] + colors[\"210\"]\n",
    "cc = (\n",
    "    []\n",
    "    + colorbytype[\"111\"]\n",
    "    + colorbytype[\"110\"]\n",
    "    + colorbytype[\"211\"]\n",
    "    + colorbytype[\"210\"]\n",
    ")\n",
    "\n",
    "links = linkage(wholeDistances, method=\"complete\")\n",
    "\n",
    "\n",
    "plt.figure( \n",
    "           dpi = 1200) \n",
    "\n",
    "plt.rcParams.update({'font.size': 32})\n",
    "cmap = clustermap(\n",
    "    wfDist,\n",
    "    method=\"complete\",\n",
    "    cmap=\"bone\",\n",
    "    tree_kws=dict(linewidths=2.5),\n",
    "    #row_colors=cr,\n",
    "    #col_colors=cc,\n",
    "    row_linkage=links,\n",
    "    col_linkage=links,\n",
    "    #linewidths=0.05,\n",
    "   dendrogram_ratio=(0.2,0.2),\n",
    "   linewidths=.75, \n",
    "    figsize=(25,25),\n",
    "    xticklabels=a2, yticklabels=a2,\n",
    "    cbar=True,\n",
    ")\n",
    "\n",
    "cmap.ax_col_dendrogram.remove()\n",
    "#_ = cmap.ax_heatmap.set_xticks([])\n",
    "#for l in cmap.ax_row_dendrogram.lines:\n",
    "        #l.set_linewidth(20)\n",
    "#for l in cmap.ax_col_dendrogram.lines:\n",
    "#        l.set_linewidth(20)\n",
    "#cmap.savefig(\"groupingDistances.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we save and classify the trajectory using the the SOAP environments defined in the complete dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surf in [110,211,210]:\n",
    "    with File(f\"{surf}.hdf5\", \"r\") as workFile:\n",
    "        g=workFile[f\"SOAP\"]\n",
    "        for key in workFile[f\"SOAP\"].keys():\n",
    "            cls = {}\n",
    "            t= classify(g[key], wholeData, SOAPdistanceNormalized, True)\n",
    "            cls[f\"whole\"] = t.references\n",
    "            cls[f\"whole_d\"] = t.distances\n",
    "            saveXYZfromTrajGroup(\n",
    "             f\"whole_{surf}_T_700.xyz\",\n",
    "             workFile[f\"Trajectories/{key}\"],\n",
    "             **cls,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production",
   "language": "python",
   "name": "production"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
