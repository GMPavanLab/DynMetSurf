{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/Scrivania/repo/SOAPify/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8.231577 -22.386938   9.71262 ]\n",
      "[0:1] 1 1 chunk of 88 B\n",
      "[  3.1659856 -24.49367     7.421548 ]\n",
      "[0:1] 1 1 chunk of 88 B\n",
      "[ 3.9309471e-09 -2.0294651e+01  9.3765564e+00]\n",
      "[0:1] 1 1 chunk of 88 B\n",
      "[-29.760317   -5.2606387   8.545859 ]\n",
      "[0:1] 1 1 chunk of 88 B\n",
      "working on trajectory chunk \"(slice(0, 1, 1), slice(0, 2400, 1), slice(0, 3, 1))\"\n",
      "   and working on box chunk \"(slice(0, 1, 1), slice(0, 6, 1))\"\n",
      "working on frames: [0:1]\n",
      "delta create= 1.9614675045013428\n",
      "working on trajectory chunk \"(slice(0, 1, 1), slice(0, 2400, 1), slice(0, 3, 1))\"\n",
      "   and working on box chunk \"(slice(0, 1, 1), slice(0, 6, 1))\"\n",
      "working on frames: [0:1]\n",
      "delta create= 1.9582798480987549\n",
      "working on trajectory chunk \"(slice(0, 1, 1), slice(0, 2304, 1), slice(0, 3, 1))\"\n",
      "   and working on box chunk \"(slice(0, 1, 1), slice(0, 6, 1))\"\n",
      "working on frames: [0:1]\n",
      "delta create= 2.084731101989746\n",
      "working on trajectory chunk \"(slice(0, 1, 1), slice(0, 2400, 1), slice(0, 3, 1))\"\n",
      "   and working on box chunk \"(slice(0, 1, 1), slice(0, 6, 1))\"\n",
      "working on frames: [0:1]\n",
      "delta create= 1.9517159461975098\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from  h5py import File\n",
    "from HDF5er import saveXYZfromTrajGroup,MDA2HDF5,saveXYZfromTrajGroup\n",
    "import numpy\n",
    "from MDAnalysis import Universe as mdaUniverse\n",
    "from SOAPify import (saponifyGroup, \n",
    "                    createReferencesFromTrajectory,\n",
    "                    mergeReferences,\n",
    "                    SOAPdistanceNormalized,\n",
    "                    saveReferences,\n",
    "                    )\n",
    "\n",
    "loadReferences=True\n",
    "soapReferences=True\n",
    "\n",
    "# %%\n",
    "if loadReferences:\n",
    "    for fname in [\"110.data\"  ,\"111.data\"  ,\"210.data\"  ,\"211.data\" ]:\n",
    "        u=mdaUniverse(fname)#, atom_style=\"id type x y z\")\n",
    "        u.atoms.types = [\"Cu\"] * len(u.atoms)\n",
    "        print(u.coord[0])\n",
    "        MDA2HDF5(u,\"bases.hdf5\",fname.split('.')[0], trajChunkSize=1000)\n",
    "\n",
    "    with File(\"bases.hdf5\",\"r\") as workFile:\n",
    "        for id in ['111','211','210','110']:\n",
    "            saveXYZfromTrajGroup(f\"{id}.xyz\",workFile[f'Trajectories/{id}'])\n",
    "if soapReferences:\n",
    "    with File(\"bases.hdf5\",\"a\") as workFile:\n",
    "        saponifyGroup(\n",
    "        trajContainers=workFile[\"Trajectories\"],\n",
    "        SOAPoutContainers=workFile.require_group(\"SOAP\"),\n",
    "        SOAPOutputChunkDim=1000,\n",
    "        SOAPnJobs=32,\n",
    "        SOAPrcut=6,    \n",
    "        SOAPnmax= 8,\n",
    "        SOAPlmax= 8,\n",
    "    )\n",
    "\n",
    "# %%\n",
    "references={}\n",
    "request={\n",
    "    \"111\":dict(s=(0,1312),ss=(0,1313),b=(0,1099)),\n",
    "    \"110\":dict(slc=(0,1072),shc=(0,1089),sslc=(0,1074),sshc=(0,1091),b=(0,1080)),\n",
    "    \"211\":dict(slc=(0,1176),smc=(0,1297),shc=(0,1202),sslc=(0,1275),ssmc=(0,1204),sshc=(0,1301),b=(0,1309)),\n",
    "    \"210\":dict(slc=(0,1320),smc=(0,1297),shc=(0,1298),sslc=(0,1611),ssmc=(0,1324),sshc=(0,1301),b=(0,1308))\n",
    "}\n",
    "with File(\"bases.hdf5\",\"r\") as workFile:\n",
    "    for k in request:\n",
    "        references[k]=createReferencesFromTrajectory(workFile[f'SOAP/{k}'],request[k],8,8)\n",
    "        for i,name in enumerate(references[k].names):\n",
    "            references[k].names[i]=f'{k}_{name}'\n",
    "    \n",
    "\n",
    "# %%\n",
    "wholeData=mergeReferences(references['111'],references['110'],references['211'],references['210'])\n",
    "ndataset=len(wholeData)\n",
    "wholeDistances=numpy.zeros((int(ndataset*(ndataset-1)/2)))\n",
    "cpos=0\n",
    "for i in range(ndataset):\n",
    "    for j in range(i+1,ndataset):\n",
    "        wholeDistances[cpos]=SOAPdistanceNormalized(wholeData.spectra[i],wholeData.spectra[j])\n",
    "        cpos+=1\n",
    "\n",
    "\n",
    "# %%\n",
    "with File(\"references.hdf5\",'w') as refFile:\n",
    "    g=refFile.require_group('testReferences')\n",
    "    for k in references:\n",
    "        saveReferences(g,k,references[k])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
